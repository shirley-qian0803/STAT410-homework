ggplot(data.frame(Components = 1:length(var_explained), Variance = cum_var_explained), aes(x = Components, y = Variance)) +
geom_line() + geom_point() +
labs(title = "Cumulative Variance Explained by Principal Components", x = "Number of Components", y = "Cumulative % Variance Explained") +
theme_minimal()
# Perform PCR with cross-validation to select optimal number of components
pcr_model <- pcr(hipcenter ~ ., data = seatpos, scale = TRUE, validation = "CV")
# Plot RMSEP to find optimal components
validationplot(pcr_model, val.type = "RMSEP")
summary(pcr_model)
names(pcr_model)
# Perform PCR with cross-validation to select optimal number of components
pcr_model <- pcr(hipcenter ~ ., data = seatpos, scale = TRUE, validation = "CV")
# Plot RMSEP to find optimal components
validationplot(pcr_model, val.type = "RMSEP")
summary(pcr_model)
names(pcr_model)
head(pcmod2$scores)
# Perform PCR with cross-validation to select optimal number of components
pcr_model <- pcr(hipcenter ~ ., data = seatpos, scale = TRUE, validation = "CV")
# Plot RMSEP to find optimal components
validationplot(pcr_model, val.type = "RMSEP")
summary(pcr_model)
names(pcr_model)
head(pcr_model$scores)
# Perform PCR with cross-validation to select optimal number of components
pcr_model <- pcr(hipcenter ~ ., data = seatpos, scale = TRUE, validation = "CV")
# Plot RMSEP to find optimal components
validationplot(pcr_model, val.type = "RMSEP")
summary(pcr_model)
# Load fat data
data(fat)
?fat
# Define response and predictor variables
y_fat <- fat$brozek
X_fat <- as.matrix(fat[, -1])
# Ridge regression with cross-validation to find optimal lambda
ridge_cv_fat <- cv.glmnet(X_fat, y_fat, alpha = 0)
ridge_model_fat <- glmnet(X_fat, y_fat, alpha = 0, lambda = ridge_cv_fat$lambda.min)
print("Ridge Regression Coefficients:")
coef(ridge_model_fat)
# Calculate and display RMSE for Ridge Regression
ridge_rmse <- rmse(y_fat, predict(ridge_model_fat, X_fat, s = ridge_cv_fat$lambda.min))
paste("RMSE for Ridge Regression:", ridge_rmse)
# LASSO regression with cross-validation to find optimal lambda
lasso_cv_fat <- cv.glmnet(X_fat, y_fat, alpha = 1)
lasso_model_fat <- glmnet(X_fat, y_fat, alpha = 1, lambda = lasso_cv_fat$lambda.min)
print("LASSO Regression Coefficients:")
coef(lasso_model_fat)
# Calculate and display RMSE for LASSO Regression
lasso_rmse <- rmse(y_fat, predict(lasso_model_fat, X_fat, s = lasso_cv_fat$lambda.min))
paste("RMSE for LASSO Regression:", lasso_rmse)
# Ridge regression with cross-validation to find optimal lambda
ridge_cv_fat <- cv.glmnet(X_fat, y_fat, alpha = 0)
ridge_model_fat <- glmnet(X_fat, y_fat, alpha = 0, lambda = ridge_cv_fat$lambda.min)
print("Ridge Regression Coefficients:")
coef(ridge_model_fat)
# Calculate and display RMSE for Ridge Regression
ridge_rmse <- rmse(y_fat, predict(ridge_model_fat, X_fat, s = ridge_cv_fat$lambda.min))
paste("RMSE for Ridge Regression:", ridge_rmse)
# LASSO regression with cross-validation to find optimal lambda
lasso_cv_fat <- cv.glmnet(X_fat, y_fat, alpha = 1)
lasso_model_fat <- glmnet(X_fat, y_fat, alpha = 1, lambda = lasso_cv_fat$lambda.min)
print("LASSO Regression Coefficients:")
coef(lasso_model_fat)
# Calculate and display RMSE for LASSO Regression
lasso_rmse <- rmse(y_fat, predict(lasso_model_fat, X_fat, s = lasso_cv_fat$lambda.min))
paste("RMSE for LASSO Regression:", lasso_rmse)
data(fat)
# Setting seed for reproducibility and splitting data
set.seed(123)
train_indices <- sample(1:nrow(fat), 0.7 * nrow(fat))
train_data <- fat[train_indices, ]
test_data <- fat[-train_indices, ]
data(fat)
# Setting seed for reproducibility and splitting data
set.seed(123)
train_indices <- sample(1:nrow(fat), 0.7 * nrow(fat))
train_data <- fat[train_indices, ]
test_data <- fat[-train_indices, ]
cfat_train <- train_data[, c("neck", "chest", "abdom", "hip", "thigh", "knee", "ankle", "biceps", "forearm", "wrist")]
cfat_test <- test_data[, c("neck", "chest", "abdom", "hip", "thigh", "knee", "ankle", "biceps", "forearm", "wrist")]
y_train <- train_data$brozek
y_test <- test_data$brozek
data(fat)
# Setting seed for reproducibility and splitting data
set.seed(123)
train_indices <- sample(1:nrow(fat), 0.7 * nrow(fat))
train_data <- fat[train_indices, ]
test_data <- fat[-train_indices, ]
cfat_train <- train_data[, c("neck", "chest", "abdom", "hip", "thigh", "knee", "ankle", "biceps", "forearm", "wrist")]
cfat_test <- test_data[, c("neck", "chest", "abdom", "hip", "thigh", "knee", "ankle", "biceps", "forearm", "wrist")]
y_train <- train_data$brozek
y_test <- test_data$brozek
# Load MASS library for ridge regression
library(MASS)
# Ridge regression with GCV to select the optimal lambda
ridge_model <- lm.ridge(y_train ~ ., data = as.data.frame(cfat_train), lambda = seq(0, 10, length = 100))
ridge_lambda <- ridge_model$lambda[which.min(ridge_model$GCV)]
ridge_coef <- coef(ridge_model)[, which.min(ridge_model$GCV)]
print("Optimal Ridge Lambda:")
ridge_lambda
print("Ridge Coefficients:")
ridge_coef
# Predict on the test set
ridge_pred <- as.matrix(cfat_test) %*% ridge_coef[-1] + ridge_coef[1]  # Using intercept + coefficients
# Load MASS library for ridge regression
library(MASS)
# Ridge regression with GCV to select the optimal lambda
ridge_model <- lm.ridge(y_train ~ ., data = as.data.frame(cfat_train), lambda = seq(0, 10, length = 100))
ridge_lambda <- ridge_model$lambda[which.min(ridge_model$GCV)]
ridge_coef <- coef(ridge_model)[, which.min(ridge_model$GCV)]
print("Optimal Ridge Lambda:")
ridge_lambda
print("Ridge Coefficients:")
ridge_coef
# Separate intercept and coefficients for prediction
ridge_intercept <- ridge_coef[1]
ridge_coefficients <- ridge_coef[-1]
# Predict on the test set
ridge_pred <- as.vector(as.matrix(cfat_test) %*% ridge_coefficients + ridge_intercept)
```{r}
# Load MASS library for ridge regression
library(MASS)
# Ridge regression with GCV to select the optimal lambda
ridge_model <- lm.ridge(y_train ~ ., data = as.data.frame(cfat_train), lambda = seq(0, 10, length = 100))
ridge_lambda <- ridge_model$lambda[which.min(ridge_model$GCV)]
ridge_coef <- coef(ridge_model)[, which.min(ridge_model$GCV)]
print("Optimal Ridge Lambda:")
ridge_lambda
print("Ridge Coefficients:")
ridge_coef
# Separate intercept and coefficients for prediction
ridge_intercept <- ridge_coef[1]
ridge_coefficients <- ridge_coef[-1]
# Convert cfat_test to a matrix and ensure alignment
cfat_test_matrix <- as.matrix(cfat_test)
# Predict on the test set
ridge_pred <- as.vector(cfat_test_matrix %*% ridge_coefficients + ridge_intercept)
# Ridge regression with a range of lambda values
ridge_model <- lm.ridge(y_train ~ ., data = as.data.frame(cfat_train), lambda = seq(0, 10, length = 100))
# Select the optimal lambda based on GCV
ridge_lambda <- ridge_model$lambda[which.min(ridge_model$GCV)]
ridge_coef <- coef(ridge_model)[, which.min(ridge_model$GCV)]
print("Optimal Ridge Lambda:")
ridge_lambda
print("Ridge Coefficients:")
ridge_coef
# Predictions and RMSE calculation on the test set
ridge_pred <- as.matrix(cfat_test) %*% ridge_coef[-1] + ridge_coef[1]  # Using intercept + coefficients
# Ridge regression with a range of lambda values
ridge_model <- lm.ridge(y_train ~ ., data = as.data.frame(cfat_train), lambda = seq(0, 10, length = 100))
# Select the optimal lambda based on GCV
ridge_lambda <- ridge_model$lambda[which.min(ridge_model$GCV)]
ridge_coef <- coef(ridge_model)[, which.min(ridge_model$GCV)]
print("Optimal Ridge Lambda:")
ridge_lambda
print("Ridge Coefficients:")
ridge_coef
print(cfat_test)
# Predictions and RMSE calculation on the test set
ridge_pred <- as.matrix(cfat_test) %*% ridge_coef[-1] + ridge_coef[1]  # Using intercept + coefficients
# Ridge regression with a range of lambda values
ridge_model <- lm.ridge(y_train ~ ., data = as.data.frame(cfat_train), lambda = seq(0, 10, length = 100))
# Select the optimal lambda based on GCV
ridge_lambda <- ridge_model$lambda[which.min(ridge_model$GCV)]
ridge_coef <- coef(ridge_model)[, which.min(ridge_model$GCV)]
print("Optimal Ridge Lambda:")
ridge_lambda
print("Ridge Coefficients:")
ridge_coef
print(cfat_test)
print(ridge_coef[-1])
# Predictions and RMSE calculation on the test set
ridge_pred <- as.matrix(cfat_test) %*% ridge_coef[-1] + ridge_coef[1]  # Using intercept + coefficients
# Ridge regression with a range of lambda values
ridge_model <- lm.ridge(y_train ~ ., data = as.data.frame(cfat_train), lambda = seq(0, 10, length = 100))
# Select the optimal lambda based on GCV
ridge_lambda <- ridge_model$lambda[which.min(ridge_model$GCV)]
ridge_coef <- coef(ridge_model)[, which.min(ridge_model$GCV)]
print("Optimal Ridge Lambda:")
ridge_lambda
print("Ridge Coefficients:")
ridge_coef
print(cfat_test)
print(ridge_coef[-1])
# Ridge regression with a range of lambda values
ridge_model <- lm.ridge(y_train ~ ., data = as.data.frame(cfat_train), lambda = seq(0, 10, length = 100))
# Select the optimal lambda based on GCV
ridge_lambda <- ridge_model$lambda[which.min(ridge_model$GCV)]
ridge_coef <- coef(ridge_model)[, which.min(ridge_model$GCV)]
print("Optimal Ridge Lambda:")
ridge_lambda
print("Ridge Coefficients:")
ridge_coef
print("cfat_test:")
print(cfat_test)
data(fat)
# Setting seed for reproducibility and splitting data
set.seed(123)
train_indices <- sample(1:nrow(fat), 0.7 * nrow(fat))
train_data <- fat[train_indices, ]
test_data <- fat[-train_indices, ]
cfat_train <- train_data[, c("neck", "chest", "abdom", "hip", "thigh", "knee", "ankle", "biceps", "forearm", "wrist")]
cfat_test <- test_data[, c("neck", "chest", "abdom", "hip", "thigh", "knee", "ankle", "biceps", "forearm", "wrist")]
y_train <- train_data$brozek
y_test <- test_data$brozek
data(fat)
# Setting seed for reproducibility and splitting data
set.seed(123)
train_indices <- sample(1:nrow(fat), 0.7 * nrow(fat))
train_data <- fat[train_indices, ]
test_data <- fat[-train_indices, ]
cfat_train <- train_data[, c("neck", "chest", "abdom", "hip", "thigh", "knee", "ankle", "biceps", "forearm", "wrist")]
cfat_test <- test_data[, c("neck", "chest", "abdom", "hip", "thigh", "knee", "ankle", "biceps", "forearm", "wrist")]
y_train <- train_data$brozek
y_test <- test_data$brozek
cfat_test
data(fat)
# Setting seed for reproducibility and splitting data
set.seed(123)
train_indices <- sample(1:nrow(fat), 0.7 * nrow(fat))
train_data <- fat[train_indices, ]
test_data <- fat[-train_indices, ]
cfat_train <- train_data[, c("neck", "chest", "abdom", "hip", "thigh", "knee", "ankle", "biceps", "forearm", "wrist")]
cfat_test <- test_data[, c("neck", "chest", "abdom", "hip", "thigh", "knee", "ankle", "biceps", "forearm", "wrist")]
y_train <- train_data$brozek
y_test <- test_data$brozek
# Ridge regression with a range of lambda values
ridge_model <- lm.ridge(y_train ~ ., data = as.data.frame(cfat_train), lambda = seq(0, 10, length = 100))
# Select the optimal lambda based on GCV
ridge_lambda <- ridge_model$lambda[which.min(ridge_model$GCV)]
ridge_coef <- coef(ridge_model)[, which.min(ridge_model$GCV)]
print("Optimal Ridge Lambda:")
ridge_lambda
print("Ridge Coefficients:")
ridge_coef
# Predictions and RMSE calculation on the test set
ridge_pred <- as.matrix(cfat_test) %*% ridge_coef[-1] + ridge_coef[1]  # Using intercept + coefficients
data(fat)
# Setting seed for reproducibility and splitting data
set.seed(123)
train_indices <- sample(1:nrow(fat), 0.7 * nrow(fat))
train_data <- fat[train_indices, ]
test_data <- fat[-train_indices, ]
cfat_train <- train_data[, c("neck", "chest", "abdom", "hip", "thigh", "knee", "ankle", "biceps", "forearm", "wrist")]
cfat_test <- test_data[, c("neck", "chest", "abdom", "hip", "thigh", "knee", "ankle", "biceps", "forearm", "wrist")]
y_train <- train_data$brozek
y_test <- test_data$brozek
cfat_test
data(fat)
# Setting seed for reproducibility and splitting data
set.seed(123)
train_indices <- sample(1:nrow(fat), 0.7 * nrow(fat))
train_data <- fat[train_indices, ]
test_data <- fat[-train_indices, ]
cfat_train <- train_data[, c("neck", "chest", "abdom", "hip", "thigh", "knee", "ankle", "biceps", "forearm", "wrist")]
cfat_test <- test_data[, c("neck", "chest", "abdom", "hip", "thigh", "knee", "ankle", "biceps", "forearm", "wrist")]
y_train <- train_data$brozek
y_test <- test_data$brozek
Print("Cfat_test")
data(fat)
# Setting seed for reproducibility and splitting data
set.seed(123)
train_indices <- sample(1:nrow(fat), 0.7 * nrow(fat))
train_data <- fat[train_indices, ]
test_data <- fat[-train_indices, ]
cfat_train <- train_data[, c("neck", "chest", "abdom", "hip", "thigh", "knee", "ankle", "biceps", "forearm", "wrist")]
cfat_test <- test_data[, c("neck", "chest", "abdom", "hip", "thigh", "knee", "ankle", "biceps", "forearm", "wrist")]
y_train <- train_data$brozek
y_test <- test_data$brozek
print("Cfat_test")
cfat_test
data(fat)
# Setting seed for reproducibility and splitting data
set.seed(123)
train_indices <- sample(1:nrow(fat), 0.7 * nrow(fat))
train_data <- fat[train_indices, ]
test_data <- fat[-train_indices, ]
cfat_train <- train_data[, c("neck", "chest", "abdom", "hip", "thigh", "knee", "ankle", "biceps", "forearm", "wrist")]
cfat_test <- test_data[, c("neck", "chest", "abdom", "hip", "thigh", "knee", "ankle", "biceps", "forearm", "wrist")]
y_train <- train_data$brozek
y_test <- test_data$brozek
print("Cfat_test")
cfat_train
data(fat)
# Setting seed for reproducibility and splitting data
set.seed(123)
train_indices <- sample(1:nrow(fat), 0.7 * nrow(fat))
train_data <- fat[train_indices, ]
test_data <- fat[-train_indices, ]
cfat_train <- train_data[, c("neck", "chest", "abdom", "hip", "thigh", "knee", "ankle", "biceps", "forearm", "wrist")]
cfat_test <- test_data[, c("neck", "chest", "abdom", "hip", "thigh", "knee", "ankle", "biceps", "forearm", "wrist")]
y_train <- train_data$brozek
y_test <- test_data$brozek
print("Cfat_test")
cfat_test
data(fat)
# Setting seed for reproducibility and splitting data
set.seed(123)
train_indices <- sample(1:nrow(fat), 0.7 * nrow(fat))
train_data <- fat[train_indices, ]
test_data <- fat[-train_indices, ]
cfat_train <- train_data[, c("neck", "chest", "abdom", "hip", "thigh", "knee", "ankle", "biceps", "forearm", "wrist")]
cfat_test <- test_data[, c("neck", "chest", "abdom", "hip", "thigh", "knee", "ankle", "biceps", "forearm", "wrist")]
y_train <- train_data$brozek
y_test <- test_data$brozek
# Ridge regression with a range of lambda values
ridge_model <- lm.ridge(y_train ~ ., data = as.data.frame(cfat_train), lambda = seq(0, 10, length = 100))
# Select the optimal lambda based on GCV
ridge_lambda <- ridge_model$lambda[which.min(ridge_model$GCV)]
ridge_coef <- coef(ridge_model)[, which.min(ridge_model$GCV)]
print("Optimal Ridge Lambda:")
ridge_lambda
print("Ridge Coefficients:")
ridge_coef
# Predictions and RMSE calculation on the test set
ridge_pred <- as.matrix(cfat_test) %*% ridge_coef[-1] + ridge_coef[1]  # Using intercept + coefficients
# Ridge regression with a range of lambda values
ridge_model <- lm.ridge(y_train ~ ., data = as.data.frame(cfat_train), lambda = seq(0, 10, length = 100))
# Select the optimal lambda based on GCV
ridge_lambda <- ridge_model$lambda[which.min(ridge_model$GCV)]
ridge_coef <- coef(ridge_model)[, which.min(ridge_model$GCV)]
print("Optimal Ridge Lambda:")
ridge_lambda
print("Ridge Coefficients:")
ridge_coef
# Predictions and RMSE calculation on the test set
ridge_pred <- as.vector(as.matrix(cfat_test) %*% ridge_weights + ridge_intercept) # Using intercept + coefficients
# Ridge regression with a range of lambda values
ridge_model <- lm.ridge(y_train ~ ., data = as.data.frame(cfat_train), lambda = seq(0, 10, length = 100))
# Select the optimal lambda based on GCV
ridge_lambda <- ridge_model$lambda[which.min(ridge_model$GCV)]
ridge_coef <- coef(ridge_model)[, which.min(ridge_model$GCV)]
print("Optimal Ridge Lambda:")
ridge_lambda
print("Ridge Coefficients:")
ridge_coef
# Separate intercept and weights
ridge_intercept <- ridge_coef[1]
ridge_weights <- as.matrix(ridge_coef[-1])  # Convert weights to matrix for multiplication
# Predictions and RMSE calculation on the test set
ridge_pred <- as.vector(as.matrix(cfat_test) %*% ridge_weights + ridge_intercept) # Using intercept + coefficients
# Ridge regression with a range of lambda values
ridge_model <- lm.ridge(y_train ~ ., data = as.data.frame(cfat_train), lambda = seq(0, 10, length = 100))
# Select the optimal lambda based on GCV
ridge_lambda <- ridge_model$lambda[which.min(ridge_model$GCV)]
ridge_coef <- coef(ridge_model)[, which.min(ridge_model$GCV)]
print("Optimal Ridge Lambda:")
ridge_lambda
print("Ridge Coefficients:")
ridge_coef
# Separate intercept and weights
ridge_intercept <- ridge_coef[1]
ridge_weights <- as.matrix(ridge_coef[-1])  # Convert weights to matrix for multiplication
# Print dimensions for debugging
print("Dimensions of cfat_test:")
print(dim(cfat_test))  # Should match the length of ridge_coef[-1]
print("Length of ridge_coef[-1] (ridge weights):")
print(length(ridge_coef[-1]))  # Should match the number of columns in cfat_test
# Predictions and RMSE calculation on the test set
ridge_pred <- as.vector(as.matrix(cfat_test) %*% ridge_weights + ridge_intercept) # Using intercept + coefficients
# Fit LASSO model with lars
lasso_model <- lars(as.matrix(cfat_train), y_train, type = "lasso")
data(fat)
# Setting seed for reproducibility and splitting data
set.seed(123)
train_indices <- sample(1:nrow(fat), 0.7 * nrow(fat))
train_data <- fat[train_indices, ]
test_data <- fat[-train_indices, ]
cfat_train <- train_data[, c("neck", "chest", "abdom", "hip", "thigh", "knee", "ankle", "biceps", "forearm", "wrist")]
cfat_test <- test_data[, c("neck", "chest", "abdom", "hip", "thigh", "knee", "ankle", "biceps", "forearm", "wrist")]
y_train <- train_data$brozek
y_test <- test_data$brozek
library(lars)
install.packages("lars")
library(lars)
# Fit LASSO model with lars
lasso_model <- lars(as.matrix(cfat_train), y_train, type = "lasso")
cv_lasso <- cv.lars(as.matrix(cfat_train), y_train, type = "lasso")
# Determine the optimal L1 norm fraction based on cross-validation
lasso_fraction <- cv_lasso$fraction[which.min(cv_lasso$cv)]
lasso_coef <- predict(lasso_model, s = lasso_fraction, type = "coef", mode = "fraction")$coef
# Predictions on test set
lasso_pred <- as.matrix(cfat_test) %*% lasso_coef
library(lars)
# Fit LASSO model with lars
lasso_model <- lars(as.matrix(cfat_train), y_train, type = "lasso")
cv_lasso <- cv.lars(as.matrix(cfat_train), y_train, type = "lasso")
# Determine the optimal L1 norm fraction based on cross-validation
lasso_fraction <- cv_lasso$fraction[which.min(cv_lasso$cv)]
lasso_coef <- predict(lasso_model, s = lasso_fraction, type = "coef", mode = "fraction")$coef
# Predictions on test set
lasso_pred <- predict(lasso_model,cfat_test,s=svm,mode="fraction")
library(lars)
# Fit LASSO model with lars
lasso_model <- lars(as.matrix(cfat_train), y_train, type = "lasso")
cv_lasso <- cv.lars(as.matrix(cfat_train), y_train, type = "lasso")
# Determine the optimal L1 norm fraction based on cross-validation
lasso_fraction <- cv_lasso$fraction[which.min(cv_lasso$cv)]
lasso_coef <- predict(lasso_model, s = lasso_fraction, type = "coef", mode = "fraction")$coef
# Predictions on test set
lasso_pred <- predict(lasso_model,cfat_test,mode="fraction")
lasso_rmse <- sqrt(mean((y_test - lasso_pred)^2))
data(fat)
# Setting seed for reproducibility and splitting data
set.seed(123)
train_indices <- sample(1:nrow(fat), 0.7 * nrow(fat))
train_data <- fat[train_indices, ]
test_data <- fat[-train_indices, ]
cfat_train <- train_data[, c("neck", "chest", "abdom", "hip", "thigh", "knee", "ankle", "biceps", "forearm", "wrist")]
cfat_test <- test_data[, c("neck", "chest", "abdom", "hip", "thigh", "knee", "ankle", "biceps", "forearm", "wrist")]
y_train <- train_data$brozek
y_test <- test_data$brozek
# Ridge Regression with Cross-Validation
ridge_cv_fat <- cv.glmnet(X_train, y_train, alpha = 0)  # alpha = 0 for Ridge
data(fat)
X_fat <- as.matrix(fat[, c("neck", "chest", "abdom", "hip", "thigh", "knee", "ankle", "biceps", "forearm", "wrist")])
y_fat <- fat$brozek
# Split data into training and testing sets
set.seed(123)
train_indices <- sample(1:nrow(X_fat), 0.7 * nrow(X_fat))
X_train <- X_fat[train_indices, ]
y_train <- y_fat[train_indices]
X_test <- X_fat[-train_indices, ]
y_test <- y_fat[-train_indices]
# Ridge Regression with Cross-Validation
ridge_cv_fat <- cv.glmnet(X_train, y_train, alpha = 0)  # alpha = 0 for Ridge
ridge_model_fat <- glmnet(X_train, y_train, alpha = 0, lambda = ridge_cv_fat$lambda.min)
# Ridge Regression Coefficients
print("Ridge Regression Coefficients:")
print(coef(ridge_model_fat))
# Predict and calculate RMSE for Ridge Regression on the test set
ridge_pred <- predict(ridge_model_fat, X_test, s = ridge_cv_fat$lambda.min)
ridge_rmse <- sqrt(mean((y_test - ridge_pred)^2))
paste("RMSE for Ridge Regression on Test Set:", ridge_rmse)
# LASSO Regression with Cross-Validation
lasso_cv_fat <- cv.glmnet(X_train, y_train, alpha = 1)  # alpha = 1 for LASSO
lasso_model_fat <- glmnet(X_train, y_train, alpha = 1, lambda = lasso_cv_fat$lambda.min)
# LASSO Regression Coefficients
print("LASSO Regression Coefficients:")
print(coef(lasso_model_fat))
# Predict and calculate RMSE for LASSO Regression on the test set
lasso_pred <- predict(lasso_model_fat, X_test, s = lasso_cv_fat$lambda.min)
lasso_rmse <- sqrt(mean((y_test - lasso_pred)^2))
paste("RMSE for LASSO Regression on Test Set:", lasso_rmse)
knitr::opts_chunk$set(echo = TRUE)
library(faraway)      # Contains the datasets
library(ggplot2)      # For data visualization
library(pls)          # For principal component regression (PCR)
library(glmnet)       # For ridge and lasso regression
library(MASS)
library(ModelMetrics) # For RMSE calculation
library(dplyr)
data(seatpos)
?seatpos
# Define response and explanatory variables
y <- seatpos$hipcenter
X <- seatpos %>% dplyr::select(-hipcenter) # Exclude hipcenter for predictors
# Perform PCA without scaling
pca_no_scale <- prcomp(X, scale = FALSE)
U_no_scale <- pca_no_scale$rotation
# Display the loading matrix U without scaling
print("Loading matrix U without scaling:")
U_no_scale
pca_scaled <- prcomp(X, scale = TRUE)
U_scaled <- pca_scaled$rotation
# Display the loading matrix U with scaling
print("Loading matrix U with scaling:")
U_scaled
# Calculate % variance explained by each component
var_explained <- pca_scaled$sdev^2 / sum(pca_scaled$sdev^2) * 100
cum_var_explained <- cumsum(var_explained)
# Plot cumulative variance explained
ggplot(data.frame(Components = 1:length(var_explained), Variance = cum_var_explained), aes(x = Components, y = Variance)) +
geom_line() + geom_point() +
labs(title = "Cumulative Variance Explained by Principal Components", x = "Number of Components", y = "Cumulative % Variance Explained") +
theme_minimal()
# Perform PCR with cross-validation to select optimal number of components
pcr_model <- pcr(hipcenter ~ ., data = seatpos, scale = TRUE, validation = "CV")
# Plot RMSEP to find optimal components
validationplot(pcr_model, val.type = "RMSEP")
summary(pcr_model)
data(fat)
X_fat <- as.matrix(fat[, c("neck", "chest", "abdom", "hip", "thigh", "knee", "ankle", "biceps", "forearm", "wrist")])
y_fat <- fat$brozek
# Split data into training and testing sets
set.seed(123)
train_indices <- sample(1:nrow(X_fat), 0.7 * nrow(X_fat))
X_train <- X_fat[train_indices, ]
y_train <- y_fat[train_indices]
X_test <- X_fat[-train_indices, ]
y_test <- y_fat[-train_indices]
# Ridge Regression with Cross-Validation
ridge_cv_fat <- cv.glmnet(X_train, y_train, alpha = 0)  # alpha = 0 for Ridge
ridge_model_fat <- glmnet(X_train, y_train, alpha = 0, lambda = ridge_cv_fat$lambda.min)
# Ridge Regression Coefficients
print("Ridge Regression Coefficients:")
print(coef(ridge_model_fat))
# Predict and calculate RMSE for Ridge Regression on the test set
ridge_pred <- predict(ridge_model_fat, X_test, s = ridge_cv_fat$lambda.min)
ridge_rmse <- sqrt(mean((y_test - ridge_pred)^2))
paste("RMSE for Ridge Regression on Test Set:", ridge_rmse)
# LASSO Regression with Cross-Validation
lasso_cv_fat <- cv.glmnet(X_train, y_train, alpha = 1)  # alpha = 1 for LASSO
lasso_model_fat <- glmnet(X_train, y_train, alpha = 1, lambda = lasso_cv_fat$lambda.min)
# LASSO Regression Coefficients
print("LASSO Regression Coefficients:")
print(coef(lasso_model_fat))
# Predict and calculate RMSE for LASSO Regression on the test set
lasso_pred <- predict(lasso_model_fat, X_test, s = lasso_cv_fat$lambda.min)
lasso_rmse <- sqrt(mean((y_test - lasso_pred)^2))
paste("RMSE for LASSO Regression on Test Set:", lasso_rmse)
